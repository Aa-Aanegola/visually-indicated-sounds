{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# from pycochleagram.cochleagram import invert_cochleagram\n",
    "from torchvision import transforms\n",
    "# from utils import waveFromCochleagram, batchWaveFromCochleagram\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from librosa.feature import spectral_centroid\n",
    "from librosa.util import peak_pick\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, dataloader, num_batches=250):\n",
    "        self.sr = 96000\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.num_batches = num_batches\n",
    "        \n",
    "    def get_metrics(self):\n",
    "        wavs = []\n",
    "        gt_wavs = []\n",
    "        '''\n",
    "        for i, data in tqdm(enumerate(self.dataloader)):\n",
    "            coch, stFrames, frame0, material = data\n",
    "            out = self.model(stFrames, frame0).detach().cpu().numpy() \n",
    "            ret = batchWaveFromCochleagram(out)\n",
    "            wavs.extend(ret)\n",
    "            print(len(wavs))\n",
    "            \n",
    "            if i >= self.num_batches-1:\n",
    "                break\n",
    "        '''\n",
    "        batch_size = 2\n",
    "        # wavs = np.random.rand(self.num_batches*batch_size, 48000)\n",
    "        # gt_wavs = np.random.rand(self.num_batches*batch_size, 48000)\n",
    "        gt_wavs = torch.load(\"../../data/gt_wavs\")\n",
    "        gt_wavs = gt_wavs.numpy()\n",
    "        wavs = torch.load(\"../../data/pred_wavs\")\n",
    "        wavs = wavs.numpy()\n",
    "        print(wavs.shape)\n",
    "\n",
    "\n",
    "        print(\"Reconstructable\")\n",
    "        print(self.reconstructable(wavs))\n",
    "        print(\"Reconstruction Loss\")\n",
    "        print(self.reconstruction_loss(wavs, gt_wavs))\n",
    "        # print(\"FFT Reconstruction Loss\")\n",
    "        # print(self.fft_reconstruction_loss(wavs, gt_wavs))\n",
    "        print(\"Loudness\")\n",
    "        print(self.loudness(wavs, gt_wavs))\n",
    "        print(\"Spectral Centroid Difference\")\n",
    "        print(self.spectral_centroid_difference(wavs, gt_wavs))\n",
    "        print(\"Peak Displacement\")\n",
    "        print(self.peak_displacement(wavs, gt_wavs))\n",
    "\n",
    "    def _plot_metric(self, metric_arr, metric=\"\"):\n",
    "        plt.hist(metric_arr)\n",
    "        plt.title(f\"{metric.capitalize()} Distribution\")\n",
    "        plt.xlabel(metric)\n",
    "        plt.show()\n",
    "    \n",
    "    def _compute_mse(self, y1, y2):\n",
    "        return np.mean((y1 - y2)**2, axis=1)\n",
    "    \n",
    "    def _compute_rmse(self, y1, y2):\n",
    "        '''standard difference metric for waveforms'''\n",
    "        return np.sqrt(np.mean((y1 - y2)**2, axis=1))\n",
    "\n",
    "    def _compute_cosine_similarity(self, y1, y2):\n",
    "        '''Used between normalized waveforms'''\n",
    "        dot = np.sum(np.multiply(y1, y2), axis=1)\n",
    "        norm = np.linalg.norm(y1, axis=1) * np.linalg.norm(y2, axis=1)\n",
    "        return dot/norm\n",
    "\n",
    "    def _pearson_correlation_coefficient(self, y1, y2):\n",
    "        '''Used to show correlation between rising and falling of the waveforms'''\n",
    "        sample_pcc = []\n",
    "        for y, _y in zip(y1, y2):\n",
    "            res = scipy.stats.pearsonr(y, _y)\n",
    "            sample_pcc.append(res[0])\n",
    "        \n",
    "        return np.array(sample_pcc)\n",
    "            \n",
    "    def reconstructable(self, wavs):\n",
    "        not_reconstructable = 0\n",
    "        for wav in wavs:\n",
    "            if np.isnan(wav).any():\n",
    "                not_reconstructable += 1\n",
    "        print(not_reconstructable, len(wavs))\n",
    "        return 1 - not_reconstructable/len(wavs)\n",
    "\n",
    "    def reconstruction_loss(self, wavs, gt_wavs, plot=False):\n",
    "        '''Uses the RMSE metric for finding difference between 2 waveforms'''\n",
    "        # Make sure to filter wavs and gt_wavs that cannot be reconstructed before this\n",
    "        sample_rmse = self._compute_rmse(wavs, gt_wavs)\n",
    "\n",
    "        if plot:\n",
    "            self._plot_metric(sample_rmse, \"reconstruction loss\")\n",
    "\n",
    "        return np.mean(sample_rmse)\n",
    "\n",
    "    def fft_reconstruction_loss(self, wavs, gt_wavs, plot=False):\n",
    "        frequencies, times, spectrograms = signal.spectrogram(wavs, self.sr)\n",
    "        gt_frequencies, gt_times, gt_spectrograms = signal.spectrogram(gt_wavs, self.sr)\n",
    "        print(spectrograms.shape)\n",
    "        sample_spectogram_rmse = self._compute_rmse(spectrograms, gt_spectrograms)\n",
    "\n",
    "        if plot:\n",
    "            self._plot_metric(sample_spectogram_rmse, \"fft reconstruction loss\")\n",
    "\n",
    "        return np.mean(sample_spectogram_rmse)\n",
    "\n",
    "    def loudness(self, wavs, gt_wavs, plot=False):\n",
    "        sample_loudness = self._compute_mse(wavs, gt_wavs)\n",
    "\n",
    "        if plot:\n",
    "            self._plot_metric(sample_loudness, \"loudness loss\")\n",
    "\n",
    "        return np.mean(sample_loudness)\n",
    "\n",
    "    def spectral_centroid_difference(self, wavs, gt_wavs, plot=False):\n",
    "        sample_centroid_difference = []\n",
    "        for wav, gt_wav in zip(wavs, gt_wavs):\n",
    "            # for each time_step one spectral centroid, indication of the domininant frequency that can be heard\n",
    "            wav_centroids = spectral_centroid(y=wav[22560:25440]+0.01, sr=self.sr)\n",
    "            gt_centroids = spectral_centroid(y=gt_wav[22560:25440]+0.01, sr=self.sr)\n",
    "\n",
    "\n",
    "            '''\n",
    "            plt.plot(range(wav_centroids.shape[1]), wav_centroids[0], label=\"pred\")\n",
    "            plt.plot(range(gt_centroids.shape[1]), gt_centroids[0], label=\"gt\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            sample_centroid_difference.append(np.mean(self._compute_rmse(wav_centroids, gt_centroids)))\n",
    "        \n",
    "        if plot:\n",
    "            self._plot_metric(sample_centroid_difference, \"spectral centroid difference\")\n",
    "\n",
    "        return np.mean(sample_centroid_difference)\n",
    "\n",
    "\n",
    "    def peak_displacement(self, wavs, gt_wavs, plot=False):\n",
    "        wavs_peak_pos = np.argmax(wavs, axis=1)\n",
    "        gt_wavs_peak_pos = np.argmax(gt_wavs, axis=1)\n",
    "        wavs_peak_pos = np.expand_dims(wavs_peak_pos, axis=-1)\n",
    "        gt_wavs_peak_pos = np.expand_dims(gt_wavs_peak_pos, axis=-1)\n",
    "        sample_peak_displacement = self._compute_rmse(wavs_peak_pos, gt_wavs_peak_pos)/96\n",
    "\n",
    "        if plot:\n",
    "            self._plot_metric(sample_peak_displacement, \"peak displacement difference\")\n",
    "        \n",
    "        return np.mean(sample_peak_displacement)\n",
    "\n",
    "    def sample_inference_time(self, wavs, plot=False):\n",
    "        pass\n",
    "\n",
    "    def material_consistency(self, wavs, gt_wavs, plot=False):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 48000)\n",
      "Reconstructable\n",
      "0 16\n",
      "1.0\n",
      "Reconstruction Loss\n",
      "0.015691975\n",
      "Loudness\n",
      "0.00028396593\n",
      "Spectral Centroid Difference\n",
      "1515.5134695382526\n",
      "Peak Displacement\n",
      "0.6087239583333334\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(None, None)\n",
    "evaluator.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([[1, 2, 3], \n",
    "               [3, 2, 1]])\n",
    "y2 = np.array([[3, 2, 1], \n",
    "               [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 188)\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "wavs = np.random.rand(230, 48000)\n",
    "wavs_onset_envelope = librosa.onset.onset_strength(y=wavs, sr=48000, hop_length=256)\n",
    "print(wavs_onset_envelope.shape)\n",
    "wavs_peak_position = librosa.util.peak_pick(x=wavs_onset_envelope[0],\n",
    "                                            pre_max=7, post_max=7, pre_avg=7, post_avg=7, delta=0.5, wait=5)\n",
    "print(wavs_peak_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9999999999999998, 1.3415758552508151e-08)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
