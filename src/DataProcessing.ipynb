{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from pycochleagram.utils import wav_to_array\n",
    "from pycochleagram.cochleagram import human_cochleagram\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "from VISDataPoint import VISDataPoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/train.txt', 'r') as f:\n",
    "    file_names = [x.strip() for x in f.readlines()] \n",
    "\n",
    "root = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDatapointsFromFile(file_name, frame_size=(224, 224), window_duration=0.5):\n",
    "    wav_file = os.path.join(root, f'{file_name}_denoised.wav')\n",
    "    video_file = os.path.join(root, f'{file_name}_denoised.mp4')\n",
    "    annotation_file = os.path.join(root, f'{file_name}_times.txt')\n",
    "\n",
    "    annotations = pd.read_csv(annotation_file, sep=' ', names=['Time', 'Material', 'Contact Type', 'Motion Type'])\n",
    "    wav, sample_rate = wav_to_array(wav_file)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        resized_frame = cv2.resize(frame, dsize=frame_size, interpolation=cv2.INTER_CUBIC)\n",
    "        frames.append(resized_frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    data_points = []\n",
    "    for row in annotations.iterrows():\n",
    "        peak_time = row[1]['Time']\n",
    "        start_time = peak_time - window_duration/2\n",
    "\n",
    "        start_frame = int(start_time * frame_rate)\n",
    "        end_frame = start_frame + int(frame_rate * window_duration)\n",
    "        window_frames = frames[start_frame-1:end_frame+2]\n",
    "\n",
    "        start_sound = int(start_time * sample_rate)\n",
    "        end_sound = start_sound + int(sample_rate * window_duration)\n",
    "        window_sound = wav[start_sound:end_sound]\n",
    "\n",
    "        coch = human_cochleagram(window_sound, sample_rate, n=40, low_lim=100, hi_lim=10000, sample_factor=1, downsample=90, nonlinearity='power')\n",
    "\n",
    "        data_points.append(VISDataPoint(coch, window_frames, row[1]['Material']))\n",
    "\n",
    "    return data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/733 [00:06<39:21,  3.23s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x3c3c680] moov atom not found\n",
      "  0%|          | 3/733 [00:06<24:36,  2.02s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x3c3b9c0] moov atom not found\n",
      "  3%|▎         | 25/733 [01:33<31:55,  2.71s/it]  [mov,mp4,m4a,3gp,3g2,mj2 @ 0x304aac0] moov atom not found\n",
      "  7%|▋         | 52/733 [03:45<1:12:03,  6.35s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x3d1a540] moov atom not found\n",
      " 10%|█         | 74/733 [04:53<52:06,  4.74s/it]  [mov,mp4,m4a,3gp,3g2,mj2 @ 0x303e000] moov atom not found\n",
      " 11%|█         | 77/733 [05:02<46:52,  4.29s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x3d1a540] moov atom not found\n",
      " 11%|█▏        | 84/733 [05:30<40:53,  3.78s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x301eac0] moov atom not found\n",
      " 12%|█▏        | 85/733 [05:30<30:59,  2.87s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x3d1a540] moov atom not found\n",
      " 19%|█▊        | 136/733 [09:26<53:09,  5.34s/it]  [mov,mp4,m4a,3gp,3g2,mj2 @ 0x3a18cc0] moov atom not found\n",
      " 36%|███▋      | 267/733 [22:06<23:15,  2.99s/it]  [mov,mp4,m4a,3gp,3g2,mj2 @ 0x304d380] moov atom not found\n",
      " 59%|█████▉    | 432/733 [39:05<44:49,  8.93s/it]  [mov,mp4,m4a,3gp,3g2,mj2 @ 0x39f8780] moov atom not found\n",
      " 70%|███████   | 514/733 [47:01<19:51,  5.44s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x50bf240] moov atom not found\n",
      " 73%|███████▎  | 534/733 [48:32<21:36,  6.51s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0xecd4900] moov atom not found\n",
      " 75%|███████▍  | 548/733 [48:53<05:03,  1.64s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0xeb4cdc0] moov atom not found\n",
      " 89%|████████▊ | 650/733 [56:58<05:42,  4.13s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x39f8780] moov atom not found\n",
      "100%|██████████| 733/733 [1:06:37<00:00,  5.45s/it]\n"
     ]
    }
   ],
   "source": [
    "n_points = 0\n",
    "n_file_fails = 0\n",
    "\n",
    "material_stats = defaultdict(int)\n",
    "\n",
    "for file_name in tqdm(file_names):\n",
    "    try:\n",
    "        data_points = createDatapointsFromFile(file_name)\n",
    "        for data_point in data_points:\n",
    "            material_stats[data_point.material] += 1\n",
    "            with open(f'/scratch/kapur/train/{n_points}.pkl', 'wb') as f:\n",
    "                pickle.dump(data_point, f)\n",
    "            n_points += 1\n",
    "    except:\n",
    "        n_file_fails += 1\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
